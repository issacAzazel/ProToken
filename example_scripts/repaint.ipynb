{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "from functools import partial\n",
    "from src.model.diffusion_transformer import DiffusionTransformer\n",
    "from train.schedulers import GaussianDiffusion\n",
    "import datetime\n",
    "from flax.jax_utils import replicate\n",
    "from functools import reduce\n",
    "\n",
    "from configs.global_config import global_config\n",
    "from configs.dit_config import dit_config\n",
    "global_config.dropout_flag = False \n",
    "\n",
    "### Load embedding \n",
    "with open('../embeddings/protoken_emb.pkl', 'rb') as f:\n",
    "    protoken_emb = jnp.array(pkl.load(f), dtype=jnp.float32)\n",
    "with open('../embeddings/aatype_emb.pkl', 'rb') as f:\n",
    "    aatype_emb = jnp.array(pkl.load(f), dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### constants\n",
    "NRES = 512\n",
    "NSAMPLE_PER_DEVICE = 8\n",
    "DIM_EMB_PTK = protoken_emb.shape[-1]\n",
    "DIM_EMB_AA = aatype_emb.shape[-1]\n",
    "DIM_EMB = DIM_EMB_PTK + DIM_EMB_AA # 40 # 32 + 8\n",
    "NDEVICES = len(jax.devices())\n",
    "\n",
    "BATCH_SIZE = NSAMPLE_PER_DEVICE * NDEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### function utils \n",
    "\n",
    "def split_multiple_rng_keys(rng_key, num_keys):\n",
    "    rng_keys = jax.random.split(rng_key, num_keys + 1)\n",
    "    return rng_keys[:-1], rng_keys[-1]\n",
    "\n",
    "def flatten_list_of_dicts(list_of_dicts):\n",
    "    ### [{a: [1,2,3,4]}] -> [{a:1}, {a:2}, {a:3}, {a:4}]\n",
    "    flattened_lists = [[{k: v[i] for k, v in d.items()} \n",
    "                        for i in range(len(next(iter(d.values()))))] for d in list_of_dicts]\n",
    "    return reduce(lambda x, y: x+y, flattened_lists, [])\n",
    "\n",
    "def protoken_emb_distance_fn(x, y):\n",
    "    x_ = x / (jnp.linalg.norm(x, axis=-1, keepdims=True) + 1e-6)\n",
    "    y_ = y / (jnp.linalg.norm(y, axis=-1, keepdims=True) + 1e-6)\n",
    "    \n",
    "    return -jnp.sum(x_ * y_, axis=-1)\n",
    "\n",
    "def aatype_emb_distance_fn(x, y):\n",
    "    return jnp.sum((x - y) ** 2, axis=-1)\n",
    "\n",
    "def aatype_index_to_resname(aatype_index):\n",
    "    restypes = [\n",
    "        'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P',\n",
    "        'S', 'T', 'W', 'Y', 'V'\n",
    "    ]\n",
    "    \n",
    "    return \"\".join([restypes[int(i)] for i in aatype_index])\n",
    "\n",
    "def resname_to_aatype_index(resnames):\n",
    "    restypes = [\n",
    "        'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P',\n",
    "        'S', 'T', 'W', 'Y', 'V'\n",
    "    ]\n",
    "    return np.array([restypes.index(a) for a in resnames], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load model & params \n",
    "dit_model = DiffusionTransformer(\n",
    "    config=dit_config, global_config=global_config\n",
    ")\n",
    "num_diffusion_timesteps = 500\n",
    "scheduler = GaussianDiffusion(num_diffusion_timesteps=num_diffusion_timesteps)\n",
    "\n",
    "#### rng keys\n",
    "rng_key = jax.random.PRNGKey(8888)\n",
    "np.random.seed(7777)\n",
    "\n",
    "##### load params\n",
    "ckpt_path = '../ckpts/PT_DiT_params_2000000.pkl'\n",
    "with open(ckpt_path, \"rb\") as f:\n",
    "    params = pkl.load(f)\n",
    "    params = jax.tree_util.tree_map(lambda x: jnp.array(x), params)\n",
    "    \n",
    "##### replicate params\n",
    "params = replicate(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### main inference functions\n",
    "jit_apply_fn = jax.jit(dit_model.apply)\n",
    "infer_protuple = True\n",
    "\n",
    "def clamp_x0_fn(x0):\n",
    "    protoken_indexes = \\\n",
    "                jnp.argmin(protoken_emb_distance_fn(x0[..., None, :protoken_emb.shape[-1]], \n",
    "                                                  protoken_emb.reshape((1,)*(len(x0.shape)-1) + protoken_emb.shape)), axis=-1)\n",
    "    if bool(infer_protuple):\n",
    "        aatype_indexes = \\\n",
    "                jnp.argmin(aatype_emb_distance_fn(x0[..., None, protoken_emb.shape[-1]:], \n",
    "                                                  aatype_emb.reshape((1,)*(len(x0.shape)-1) + aatype_emb.shape)), axis=-1)\n",
    "        return jnp.concatenate([protoken_emb[protoken_indexes], aatype_emb[aatype_indexes]], axis=-1)\n",
    "    else:\n",
    "        return protoken_emb[protoken_indexes]\n",
    "\n",
    "def denoise_step(params, x, seq_mask, t, residue_index, rng_key,\n",
    "                 clamp_x0_fn=None):\n",
    "    t = jnp.full((x.shape[0],), t)\n",
    "    indicator = params['params']['protoken_indicator']\n",
    "    if bool(infer_protuple):\n",
    "        indicator = jnp.concatenate([indicator, params['params']['aatype_indicator']], \n",
    "                                    axis=-1)\n",
    "    eps_prime = jit_apply_fn({'params': params['params']['model']}, x + indicator[None, ...], \n",
    "                             seq_mask, t, tokens_rope_index=residue_index)\n",
    "    mean, variance, log_variance = scheduler.p_mean_variance(x, t, eps_prime, clip=False, clamp_x0_fn=clamp_x0_fn)\n",
    "    rng_key, normal_key = jax.random.split(rng_key)\n",
    "    x = mean + jnp.exp(0.5 * log_variance) * jax.random.normal(normal_key, x.shape)\n",
    "    return x, rng_key\n",
    "\n",
    "def q_sample(x, t, rng_key):\n",
    "    t = jnp.full((x.shape[0], ), t)\n",
    "    rng_key, normal_key = jax.random.split(rng_key)\n",
    "    eps = jax.random.normal(normal_key, x.shape, dtype=jnp.float32)\n",
    "    x_t = scheduler.q_sample(x, t, eps)\n",
    "    return x_t, rng_key\n",
    "\n",
    "def noise_step(x, t, rng_key):\n",
    "    t = jnp.full((x.shape[0], ), t)\n",
    "    rng_key, normal_key = jax.random.split(rng_key)\n",
    "    x = scheduler.q_sample_step(x, t, jax.random.normal(normal_key, x.shape))\n",
    "    return x, rng_key\n",
    "\n",
    "def index_from_embedding(x):\n",
    "    # x: (B, Nres, Nemb)\n",
    "    protoken_indexes = \\\n",
    "        jnp.argmin(protoken_emb_distance_fn(x[..., None, :protoken_emb.shape[-1]], \n",
    "                                            protoken_emb[None, None, ...]), axis=-1)\n",
    "    ret = {'protoken_indexes': protoken_indexes}\n",
    "    if bool(infer_protuple):\n",
    "        aatype_indexes = \\\n",
    "            jnp.argmin(aatype_emb_distance_fn(x[..., None, protoken_emb.shape[-1]:], \n",
    "                                                aatype_emb[None, None, ...]), axis=-1)\n",
    "        ret.update({'aatype_indexes': aatype_indexes})\n",
    "        \n",
    "    return ret            \n",
    "    \n",
    "pjit_denoise_step = jax.pmap(jax.jit(partial(denoise_step, clamp_x0_fn=None)), axis_name=\"i\", \n",
    "                            in_axes=(0, 0, 0, None, 0, 0))\n",
    "pjit_denoise_step_clamped = jax.pmap(jax.jit(partial(denoise_step, clamp_x0_fn=clamp_x0_fn)), axis_name=\"i\", \n",
    "                            in_axes=(0, 0, 0, None, 0, 0))\n",
    "pjit_q_sample = jax.pmap(jax.jit(noise_step), axis_name=\"i\",\n",
    "                            in_axes=(0, None, 0))\n",
    "pjit_noise_step = jax.pmap(jax.jit(noise_step), axis_name=\"i\",\n",
    "                            in_axes=(0, None, 0))\n",
    "pjit_index_from_embedding = jax.pmap(jax.jit(index_from_embedding), axis_name=\"i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RePaint Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_repaint_info(aatypes, protokens, aatype_context_ids, protoken_context_ids):\n",
    "    protoken_context = protoken_emb[protokens]\n",
    "    aatype_context = aatype_emb[aatypes]\n",
    "    assert len(protoken_context) == len(aatype_context), 'seq_len mismatch: {} != {}'.format(len(protoken_context), len(aatype_context))\n",
    "    seq_len = len(protoken_context)\n",
    "    \n",
    "    repaint_context = np.concatenate([protoken_context, aatype_context], axis=-1)\n",
    "    repaint_mask_aa = np.array([[0,]*DIM_EMB_PTK+[1,]*DIM_EMB_AA if i in aatype_context_ids \\\n",
    "                                  else [0,]*DIM_EMB for i in range(seq_len)], \n",
    "                                dtype=np.bool_)\n",
    "    repaint_mask_ptk = np.array([[1,]*DIM_EMB_PTK+[0,]*DIM_EMB_AA if i in protoken_context_ids \\\n",
    "                                  else [0,]*DIM_EMB for i in range(seq_len)], \n",
    "                                dtype=np.bool_)\n",
    "            \n",
    "    return repaint_context, np.logical_or(repaint_mask_aa, repaint_mask_ptk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eq_steps = 50 ### more n eq steps -> higher quality, in RePaint, we recommand more n eq steps\n",
    "phasing_time = 250 ### controls balance between diversity & quality, larger phasing time -> higer quality, lower diversity\n",
    "def run_infer(x, seq_mask, residue_index, rng_keys, \n",
    "              repaint_context=None, repaint_mask=None, repaint_time_steps=np.arange(num_diffusion_timesteps)):\n",
    "    for ti in tqdm(range(num_diffusion_timesteps)):\n",
    "        t = num_diffusion_timesteps - ti\n",
    "        for eq_step in range(n_eq_steps):\n",
    "            denoise_fn = pjit_denoise_step if t > phasing_time else pjit_denoise_step_clamped\n",
    "            x, rng_keys = denoise_fn(params, x, seq_mask, t, residue_index, rng_keys)\n",
    "            x, rng_keys = pjit_noise_step(x, t, rng_keys)\n",
    "            \n",
    "            if repaint_context is not None and t in repaint_time_steps:\n",
    "                repaint_context_ = repaint_context[..., t-1] if len(repaint_context.shape) > len(x.shape) \\\n",
    "                                    else repaint_context\n",
    "                repaint_mask_ = repaint_mask[..., t-1] if len(repaint_mask.shape) > len(x.shape) \\\n",
    "                                    else repaint_mask\n",
    "                \n",
    "                repaint_context_t, rng_keys = pjit_q_sample(repaint_context_, t, rng_keys)\n",
    "                x = repaint_mask_ * repaint_context_t + (1 - repaint_mask_) * x\n",
    "            \n",
    "        x, rng_keys = denoise_fn(params, x, seq_mask, t, residue_index, rng_keys)\n",
    "\n",
    "    ret = {'embedding': x, 'seq_mask': seq_mask, 'residue_index': residue_index}\n",
    "    ret.update(pjit_index_from_embedding(x))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Contextual) Inverse Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 09:49:01.690842: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now inference pdbs at: ..//example_scripts/results/inverse_folding, \n",
      "Example: ..//example_scripts/results/inverse_folding/8CYK_B.pdb\n",
      "Total validation pdb number: 1\n",
      "Saving pdb at: ..//example_scripts/results/inverse_folding/stage_1/inference_pdbs, \n",
      "Example: ..//example_scripts/results/inverse_folding/stage_1/inference_pdbs/8CYK_B.pdb\n",
      "\tBATCH_SIZE: 16\n",
      "==============now processing 0 to 1===============\n",
      "pdb names in every device:  8CYK_B\n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "Not enough data for sharding, extend the last data.\n",
      "VALID_DATA_NUM: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 09:51:36.620354: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 1; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-14 09:51:36.620425: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 5; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-14 09:51:36.620464: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 7; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-14 09:51:36.620496: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 3; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-14 09:51:36.620576: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 2; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-14 09:51:36.620651: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 6; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-14 09:51:36.620718: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 0; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-14 09:52:04.662637: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-14 09:52:04.662732: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-14 09:52:04.662801: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-14 09:52:04.662871: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-14 09:52:04.662938: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-14 09:52:04.663008: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-14 09:52:04.663061: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdb saved at: ..//example_scripts/results/inverse_folding/stage_1/inference_pdbs/8CYK_B.pdb \n",
      "seq_len: 129\n",
      "preprocessing time: 27.764188s\n",
      "inference time: 80.605927s\n",
      "code_usage: 0.0078125\n",
      "total time: 108.370115s\n",
      "seq_len_max: 129, seq_len_min: 129\n",
      "stage_1 finished.\n",
      "pdb, loss_aux, seq_len_dict, vq_code_indexes_dict saved at ..//example_scripts/results/inverse_folding/stage_1\n",
      "All finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### example: 8CYK\n",
    "\n",
    "### obatin ProTokens\n",
    "working_dir = '../'\n",
    "os.system(f'''export PYTHONPATH={working_dir}/PROTOKEN\n",
    "          python {working_dir}/PROTOKEN/scripts/infer_batch.py\\\n",
    "            --encoder_config {working_dir}/PROTOKEN/config/encoder.yaml\\\n",
    "            --decoder_config {working_dir}/PROTOKEN/config/decoder.yaml\\\n",
    "            --vq_config {working_dir}/PROTOKEN/config/vq.yaml\\\n",
    "            --pdb_dir_path {working_dir}/example_scripts/results/inverse_folding\\\n",
    "            --save_dir_path {working_dir}/example_scripts/results/inverse_folding\\\n",
    "            --load_ckpt_path {working_dir}/ckpts/protoken_params_100000.pkl''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_mask (129,) bool\n",
      "residue_index (129,) int32\n"
     ]
    }
   ],
   "source": [
    "### load context\n",
    "with open('./results/inverse_folding/stage_1/generator_inputs/8CYK_B.pkl', 'rb') as f:\n",
    "    data_dict = pkl.load(f)\n",
    "\n",
    "seq_len = len(data_dict['protokens'])\n",
    "seq_mask = np.ones(seq_len, dtype=np.bool_)\n",
    "residue_index = np.arange(seq_len, dtype=np.int32)\n",
    "protoken_context = data_dict['protokens'].astype(np.int32)\n",
    "aatype_context = data_dict['aatype'].astype(np.int32)\n",
    "\n",
    "input_dict = {\n",
    "    'seq_mask': seq_mask, 'residue_index': residue_index,\n",
    "}\n",
    "\n",
    "for k, v in input_dict.items(): print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repaint_context (129, 40) float32\n",
      "repaint_mask (129, 40) float32\n"
     ]
    }
   ],
   "source": [
    "protoken_context_resids = np.arange(seq_len)\n",
    "#### contextual inverse folding: put sequence context here\n",
    "aatype_context_resids = [] \n",
    "\n",
    "repaint_context, repaint_mask = make_repaint_info(aatype_context, protoken_context, aatype_context_resids, protoken_context_resids)\n",
    "\n",
    "repaint_dict = {\n",
    "    'repaint_context': repaint_context, 'repaint_mask': repaint_mask.astype(np.float32)\n",
    "}\n",
    "for k, v in repaint_dict.items(): print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residue_index (8, 8, 512) int32\n",
      "seq_mask (8, 8, 512) bool\n",
      "x (8, 8, 512, 40) float32\n",
      "repaint_context (8, 8, 512, 40) float32\n",
      "repaint_mask (8, 8, 512, 40) float32\n"
     ]
    }
   ],
   "source": [
    "### preprocessing inputs\n",
    "\n",
    "def reshape_tile_pad_x(x):\n",
    "    x_shape = x.shape\n",
    "    x = np.pad(x, ((0, NRES - x_shape[0]), ) + ((0,0),) * (len(x_shape) - 1))\n",
    "    x_shape = x.shape\n",
    "    \n",
    "    x = np.tile(x[None, ...], (BATCH_SIZE, ) + (1, ) * len(x_shape))\n",
    "    x = x.reshape(NDEVICES, NSAMPLE_PER_DEVICE, *x_shape)\n",
    "    return x\n",
    "\n",
    "input_dict = jax.tree.map(\n",
    "    lambda x: jnp.array(reshape_tile_pad_x(x)), input_dict\n",
    ")\n",
    "repaint_dict = jax.tree.map(\n",
    "    lambda x: jnp.array(reshape_tile_pad_x(x)), repaint_dict\n",
    ")\n",
    "\n",
    "init_key, rng_key = jax.random.split(rng_key)\n",
    "x = jax.random.normal(init_key, (NDEVICES, NSAMPLE_PER_DEVICE, NRES, DIM_EMB))\n",
    "input_dict['x'] = x\n",
    "\n",
    "rng_keys, rng_key = split_multiple_rng_keys(rng_key, NDEVICES)\n",
    "rng_keys = jnp.reshape(rng_keys, (NDEVICES, -1))\n",
    "\n",
    "for k, v in input_dict.items(): print(k, v.shape, v.dtype)\n",
    "for k, v in repaint_dict.items(): print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [16:54<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "ret = run_infer(input_dict['x'], input_dict['seq_mask'], input_dict['residue_index'], rng_keys,\n",
    "                repaint_dict['repaint_context'], repaint_dict['repaint_mask'])\n",
    "\n",
    "ret = jax.tree_util.tree_map(lambda x: np.array(x.reshape(BATCH_SIZE, *x.shape[2:])).tolist(), ret)\n",
    "with open('results/inverse_folding/result.pkl', 'wb') as f:\n",
    "    pkl.dump(ret, f)\n",
    "    \n",
    "ret_ = flatten_list_of_dicts([ret])\n",
    "with open('results/inverse_folding/result_flatten.pkl', 'wb') as f:\n",
    "    pkl.dump(ret_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq0: METVVLKIKKGEELLAVLDYLYRSPDEDAIIELEIVDPKVKNLIAETIIMAAKELGADEEKIEALHNMINAKGVRDIYVKLKVKEEEYTIELVAELIDGRSAPITFTFNDKNGFLHILDLIRKQLKKLE\n",
      "seq1: MAKREVMIDTPDEVIESLDHYRRSKSDVDEINFRFSDKQHKNLFIREVVEVAAKNDLPENQVKKMDEELKGPHTVDVDIEVYVKKDTFLITVRAVGKDGVVGSASFVASNEQHVERLAAAVGAAMDRAS\n",
      "seq2: DRTIEMNVETANQLLEGVDRVYDLTEEDIIVKFDIEDIKGKLSLVEGLFRLVEELGADPLLVETLNGYLKSQDSIAVEITIRYEDGMFHLNVETHLDTNGVGGMLLTLENFDEARKFIRKIEKALSNLF\n",
      "seq3: SKITKTEVKNTKELIFKLDSVCNSKSEIVTGIYLIDNNEIHISLGYTIIKNLNELENSNQKLSYMQERINSDDTNYLVLVAQRYNNNFCLQISINFKSGRTESVCYEFDNLEAFFQQMSAIAKSVEELG\n",
      "seq4: MHTENKTVNAQQDLIILIRQIYKDSSPKDELSLEIDNDHVADLLANACAEVAKSQGMAKGTLDSLREGIESESTKHIKLDFRRSMQYYSLEFEFEYENDTKQKLVLTAPEEEKLRNLLTKLENLISKLK\n",
      "seq5: SRFYIITVTTIEEVQETLLRLVSSTDEHLYIKFRIRDPELVRLIALCVRQALLDLRADEKLLGRLQEMLESFHYRDCCIELRKGIALYELDFLVNLRDGTKQTYMLHSADFSKVRGLIDKIAGKFRTLQ\n",
      "seq6: SILFFREIHTVQEVTETLLRIFNQKSLAIDAEFRVSDKQLAVVLAVAIVETFKDMGFREVSLNHVRMFLDSVNFIDLGLEFKHTSTKLFIDIIAKAPDGETSKLSYSADDIDQFKSILLSIKSVIKGLE\n",
      "seq7: MRNMRWHVRSRADLRDELAGLKASDADIQRVEVYIDHPTIANWLAELAMSSLETLSLDPWLFQELTEQCGTDGFVRLQLKLWHEQSSGWILVTATFGDGCSSEVMLTAPNGEALQTLAQTVWQRLDGID\n",
      "seq8: RPLYEVRVDSWEELLEFLDRVLAEDRPEYELLFVVEERPLAAALAETVVETARELGSSEAVVDLLRSGLGEEGLASLRLRVTVREEQLKVTLSAERSDRQSVSASLAGVDLEELLALLEAVRMAVSTVS\n",
      "seq9: MAQLEEFVPSWDQLKRAVFYVDSTKHNVVLLRLGLNEPELRQALASAVERTLERLGASTEAIEQLNSFLAGKGTVDLILEVRIEGRRYLLTLKLERVDGSSGEVEQNAGDREGLMELIDEVEAAFSSLQ\n",
      "seq10: SGRIEVELSSIADLVNEISLIRAQKFKDYELVLELDDMNIINLLTRTIIEALKTYGSEEQEISKFSEDIFGPNIISLGISLEYLGDNFDFIIEKYDQSLNQKHYSITGESLSDLSGIFDLIEKAITNLK\n",
      "seq11: ALLFRKQLRTIDELKDRVKMIHDQKGDSMAVEYEVEDPHICKKVAEMIVEVLKDLDTEPHVIQEIGAAFINKQIKHLKVVFRNYYGEFRLSVKVTTEARHSATVEVPAGDRARAKYLLEKIEYLIREIE\n",
      "seq12: LPILVKDINREEELLTSIKELYLSEEQEFRVVFSIKNKVLKYFIAKTCIETLLDLNISNEQVKILLQTFEKIGNIGIQLLYVIHNKDSYLVFKQYTTSNRESKIVFEFPNKDEMQTFMALIIMEVRKFF\n",
      "seq13: AHVTTVSATTVDEMRLFIEEIRSSSEKNPEITVVVTDVERAQQLSNTLYGACKDLWGNPEEILLTKQAFNAPEHQMIQVLVSYSSISYGMEVTGILQHGRGRQIQITAAGLSQLLEVLSVIEVQLASCE\n",
      "seq14: SAVQTRDLHSAEELVSALGAALADQTGTPVQVIRIEDRALRTLVADTLVQTARQLGGNAGSIQQLRDALQEPGFRDITLRVVRAEGRFSIELTATRADGRSASIRISAPDAARAAGLLGTVRRQLARIG\n",
      "seq15: MVKETKTVDTAEEMVKALRYACDQSDMNTILVYETANPALIRALCSALANMAQKAGAHAHTIRLIEDSLNASGVFRVDISVHVDGGDASVLLHVRTVDGTRGHLSVTAANREEVGALIHAIDTELSALA\n",
      "seq16: MDEKVMDLHSLEELKSALKEIKASSKKEVRVRLRLEEKDVAKALSQAVVEAGKLLGHSVEDFHEAWRRLQSDGVKRLELSLSLEGSNYALHIEDTQQDGSTAKIRFRAANQTSVRDVLKAIDLALSTLK\n",
      "seq17: LASTEEEVSTIEDLKAQLDRALFEDEIVISVRISTPSAERVRALGAGLAAAAREMDAPIGEWERFDAAIEGEEIVSVEIELAHRGREARITIRATTLDGSSAQWTFDFASLSEFKEAVAVLRQSMITLE\n",
      "seq18: LEKLEVPVNTSKALIDQIKTIKESMAKTDRAVYQINDGQMKKILGQSVVKALKELNMNEEQVQTLQNELYSPGVEEFTISFIVENKKIFLQISAIFVNQSSASCSFVADNYEELVGLLSVCEKHMADGD\n",
      "seq19: MMIIKKEIESYLELIHKFETIESAQSSAYITEIIINSKKSAKIIESSIIQAIKDFGLESLEIKNIIKSVERKNNTRIRLRLVKFGSFHELEIDVKLQNHNVIKIKIKFDNENILKKYLDLIRIGLSLIE\n",
      "seq20: FATVNVDVNDLDDLIQQHELAVSDSSALISVRFELDGLPEAMYLGFTVASATKQLGQPPQDIAGINQALGADGIERIEITVSWDGSGFTITIQAILEDNDRTEFTFSGNGTVDIQQFIQAIENSLRSID\n",
      "seq21: STMKTVHCKTRDELLTELERYEKNKKRQNASKVVIQDSSFGFILGETLIALAKELKVEPGQLAHLKEWLEADDICTVALIFTYKDGQFSLLIIAENCNGDKDEVRFEAPNLNSLKKLKHLFVVQLKKLI\n",
      "seq22: ARQEVETILSFETLQTKIEAVLRRNGAVQSFEIHIGDRAFSEKIVRYVVMILRELGARESEIAALESVLGEPNVTSLAIVLGQKETDIKVTFQCFLAGGRTARKSIFATNSEGLFRLLGMLERDLAKVT\n",
      "seq23: TVTLKMNIDTHKELVESLDAIRNSDYSDLMYTAALSKAGMKKNLANAIIDMFRDLDADPGQLDRLKRRLESAGVVEVSISIQSDDGKYKLDIEIRSENDDADKIMFDGPNRMALNQVIEKLVESLREYF\n",
      "seq24: MNIIEQSVDTFTQITLKLSDYFNSTDKQFVIKYLLTNPAICNIFGNAFMEGMKVYGSDEKKVLSLKEMLNSPENTNLDVILNKREGSFYISVQFKFKNGMTLWEHISPRNEFEFKQLIEIIIERIKNLY\n",
      "seq25: GKVRTVDVATLETLVEHLHFFHESKEPKLKVKLVLTDLSLRTKLARVCAGIFRELGAPEESVDILTTTLTGDGLVDVRIDISKKGEQNWITVLARYADGRTSRWEFVAPDAETTRRALIKLQETLRQYR\n",
      "seq26: LNLWRQPVRRPDELREEVQFVADEDTGARGLSLHLSNPSLLNEFAFFLARLATELGLIEGEVEDFLRSLRYAGVDFLAVELVREGAELQLEIVVTESHGLSFPAVYTADDGASLIELLKRFGARLGTLP\n",
      "seq27: KSVLEMEVRDLADVKESLRHIENSKQSSPRIKFVVTELAISRWVGSRLVRIARELGAAEEQVDDFSQEIEAEEVEELEITLYRSEDYYSLEVICKLLDGREGACSVQANGEAEFRRLIARIELEAQTRE\n",
      "seq28: AAKKTIQITSLHEIKQALDYIATSTEDNIILTFVISDTSLSSALGTAIAKIAMEAKVDENLIRSLGKICNGAGITILAMDISFNSNDYIISITAITSDSSSATLTMSGQNRESFLMLIMVINNEIGNLP\n",
      "seq29: MTKREIKCSEVNDLIKKMDEIARLKLGYQSLTFTFSDLKLTRQIARSLINAAGEQELSPKQIGNLSEFLNQDDVISINFRISYKNKKLTVDIVAKKNDGSSGSLKIEGGNTSNIINLLNYLQNTIQNLE\n",
      "seq30: GHMSVLQITSVEGLLVNIEAAFADETYDPWIDIVVEDPLLTQAVAAAVVDAAHDCGGEKQQVRELSSVACDKNVRRFYLRFEFKGDNLKIEIIGTTQDESTAKVLIPCWDRCQIAGMLAHIKRALGRLK\n",
      "seq31: LRTETINASSVNDIVDELSVILNREEAYSKIELVFQDTKLKNDIADALMKSCSTLRSSKAEIKTLEEAIEAPGNSSITIQITLSKRRFVLDIVAETVDGAKGELDYPLMNQNSLASIIKKIERMIKNIE\n",
      "seq32: IKVQQIKVESDDELIDTLEKYIQSTLSNITLRLHIDDKEKSSKLVITIILVIKELNLDEHEVKEMESFLNGKNIIHIEFDLTANYHEFWLTIKITLNDKNSKTFVLKFNNLYEAVKFLEKLKIMLMRLS\n",
      "seq33: VERITLNIRSQQQFGDAIEQIRQFDSDEFSVILQIDDPALRRTVGDMLGEALRRAGIDEADLQEFEKALSSEDVVELDVLINRKQSDTTITFTASAPDGRSASISQGASNLESLRELIELISKELSTLD\n",
      "seq34: GLYRIINCSSIGDIVQVVDKIRNEAYPNNNFIISIENKNETILIAELLFRSAKELGAEEEALDSIREIKRSPGTLYLTIDVIFDGRGVFLDITAETLNNEIARFSIIADNEKDFRKYLHLIRQSLSQID\n",
      "seq35: LHEQQINISTPKELTNTISWLRAATRKDHAVRLQVLDASQARLWGNTIAKIAERDGVDPELIAEFDALFKGDNNNTISIEFLNGGKFFGLRLEVVLCDKQKGVKAVTFEDREQFLGFLLSIEQSFRLLP\n",
      "seq36: MPEREITINSTAAVAKGLNIALNDKEVMQQLMVQLNDQTIQRSLSTLIIETTISMGSPVYIIDLAYIDFKSADYEETQLSLHYKNAYYSLIIKTAYKNHHSSSVLIPAKSRNQVVQFATILVNSLLAEI\n",
      "seq37: GVIRIKELKSGDDLIAALDHFSRQPDPYDVIEYEYTSPDTARLMASAIVSAAKRLSRSETEIATLDKCLKGPGFERLRLRFSYQSGQRRLTFTAERADGRKAQVEYQFESGDEVQQLLEELKAALSMAP\n",
      "seq38: MIVTTIELKSRHDFERLIGELVQQESLDLKFVYTLNSADLQEDVGGAVLKSAVDANHSRAEIERIAEALGSPEIVNISISLRQQGERFRLDFTAVLKSGDTSTYLFEFGDRSKAKGLLKAVHQKLQQLS\n",
      "seq39: SLQITIDVESLEDLIIQIKNFRGRSEPFFSATLDIGDPILRKKLANTIISSCKKLGYDENKINEFKGFLEDKDISQLNLEIYQNLNKYILTLKAIKKNDNKAEVGFDANNYDEYQQLIDLIDNSLKTLP\n",
      "seq40: MNIKTVHLNKPSALITSCEQLLKDTGDISEVDIEVNRSATANKIATAVIESVLALGAEEEEVEEVEEMVNGSKVNKIVLRLKMDTGEYFVELSAIFANGSFKKLFFKAKSGEEVKSYVEGIKKQIENNY\n",
      "seq41: KRTMTLIVSERQELIRALQLLQSETASHGIVNFSFADKEDRLVLGDTVVDIAGRLGADEDQVTLLRNMVEGTGCESVQVSVNYDEDDFWLEISANRFNGSGGRAFIRFADRAAGLLLLQQMRLELAEME\n",
      "seq42: GKITKVQLTHPADLQQALAKTAASPDEAEETTFCLDRQDVMHALAKAVADVAQQMGADKADQQALAMALTAEGCDGVEVQLSYQDGHWYVDFTLTLEGARKEQIQLRFPDREQARQALEQLAMVSRSYL\n",
      "seq43: FRILHRSVYTPKDLVRQLEALFQEDFSVSHAFFSISKVETVHQLGASVLKVCRELGSSNAVSKMIESYLSSSGVQEVAIWLDYGDKMIVLSIETKTQEGLENRFVISCPSRIDFKAFATKIDVLLSQLP\n",
      "seq44: ENTESFKVRTLDELIVLVEEMAESEDEYHTVSLVVDEPQLASVMSKTLAAVSIELGADEDLIASIDELLNGKGVDEVFFSYKFYQEKFMLSVWAKFRNEDIAKFDLDGSNAKSLRQLLEQFKLKVERIP\n",
      "seq45: AKRFSVEVSSVADLSALVEWTARAQSSRQVLIARSHDLDGTLALAQAFVRAASELGVDARSVKELDEILQASGVDQVVLELHFGEGQYSVRLSAFFADQDEARCALYAPDAAAFQNLLEALQQSVASLG\n",
      "seq46: GIEKVIEVKTLEDIIKILDESIYNREDVSRIIFKITDLHLNRLFSETLYQQLLFLNIDKKELNKFIDFLQSSEITEYDFFLQYSNDSYSIELSTTTKSESEEKFIYNAVDKDKLLTIINKYKDSLHRID\n",
      "seq47: MRREVVFASSPEQLRKVIRRIERAEVGDWFVEIEIQEPKVRKILANSVYDGARNEGFKTNTATALNTASESSETQELSFEIQWENNVYRIEVKAQLANGTSFLLVFQAGDQGSVKRLADLVISALSTVN\n",
      "seq48: MIWNTQKVESIDDFIDKLNYLKSSGSQYDYQEYKVRSGDLKNAVGETIIKTCQELGLEEARLLTMKTALEQEGFIEIIFHLQRKNGEICYSIDAVDQEGNIDTAIVTFNDLNGLLNFANQLEASLRTLD\n",
      "seq49: EMTTTVHITTLEALVKLVDQVVHADQGEVSVTLDATDTVIRQHIGEALVAASKRLGSDPETIDRLRRWLRADSLHTLHVDVRYTDGGATLELQAVLSDGFSNSWSLEAADARALRGLLQELARELSTLA\n",
      "seq50: GTNREEVIKNWGDIVNKLGTFNESKNDDDIIQLTIKDGIIRKAVSKSLIDIAKELNVNPNVIGQWDDYVTSEKFKEIILQLCQQNDRYEIEIKATLSNNINSALVIDLGNIKSFMRIVDKLREKLNIWI\n",
      "seq51: MIKLKRSVYSVDEIFNELKYVINNDNNYNNIIIEIKDIPILKNLINCIIKKGKKIGGNKREIATIENELNSENIIDTSLYLSYESSYLTLEIDIKKKDGNITNLILPFPSKSMIASLLSEIDTILRSFK\n",
      "seq52: SHHMSVNIKNPHEIIDALDIAKSQTGFDKQLIFDVSDPNLQEVLSNAVCAAACRLQSDEAELSMMKQIMNSDGNTSLEIDIKYGDHHYHIEIHAHSVNDVEGKMTYEGIDENECKNFVLAVKKAIMKLL\n",
      "seq53: FEEDRIVASSLSQLAGWLHKLKKVEQGYVIVEWTIDSEDLRGLICDTLVGELKDLGAPDSLFKEQRQAIDGSAIKQIFFKITKKGANYVVGIGYIKEDNTSGLETWVANDRDSLYRWLDKLIKRLRTLE\n",
      "seq54: SPEETRDMTSLEDLNSEILLMREVNSDFYTHTFILDDKVHANTLAKSCALLAGKLGSATTSLQELEKFLNAEGFKRLSLEVRFNGDVYGLTVYAKLGDALQGNTRITAPDKQSLLSTIEDIALKLRALN\n",
      "seq55: GQDREENIKTLDAFIGRLDYIKNSKDDRTFIELIFDDKKTAKRVGSALIKSSIKAGINEKDVEALENVYAGEGVTETKLLIKYREGKWKLQISATFNDDGKAIKTFEGKEKDELVKLMNEIKKALASFV\n",
      "seq56: MKTKEVGLYNISSLKKRIDEIYDSSEKEYEIFFTIDKPNYVEIYSRFLVEILSEQDLSKRSLTELKNFLKEKDVDKITIKIKNSKNDFQLYLHAKTKNNKVKHLKPNFTDRNTFINFVKKIYDAIEELD\n",
      "seq57: KMKETIEIKTIEELINAINAFYKYPNGDIIKVLKIQSSVLTSKLTLAIAKAASSLGADAETIEELKKTVEAEGVKSISLEIVISADVAFIELRTIKQNDAENSLVIQAKDKEDLIQLIQDIRLAVATIE\n",
      "seq58: TAVQTRPVDTVNELAAAVAKMLAASSQAVTLTVQLPHPQLAGALAQALAEAARRQGAAQDDLDAVQRALEEPGLVGLELRLVFTDGTMELTIEATAQDGTVAETVLDAADALGLQAHARAVLDTVKGVG\n",
      "seq59: AVQTAAAVNSAGDLVQWLRGMKSSSEKSFQVNCQFQNPEFQKFLAEAIIQFATEAALDEDLIQNMKRAVTADDVESLNLIVSHRLEKFGIIIKAVLASGQQASWQIPAPDHESLVSLLEMVDAVMREIL\n",
      "seq60: LELKEEHLNSLEDLTAKLDHVIGADEDYPVATFNVDNTEVSKLLANALGKEAAQKGTRPDYLGSLEALSRSQGIGQMELRLQYDGDEFKCSIRIIFYAKLGKMISHWATDFHQLKQWLDQIRGALYRDG\n",
      "seq61: FDTVSKDFTSLTDLKEFLLSVRNSTDSKTVLSFKLNDNELMQKFSTSTVSVMYDLSLSQNNLLNLEDFFNQQDITEVIFQLSNREDHFELALLGTLSSESKAHFSFPAVDGESLTTLLEKFESQLSLLP\n",
      "seq62: FFILTMRVNTKEEMIDKLDNVRNSLKEFKYITLKIEDIEKGKYLGNALMEAIKKLKSNPLELENVERIIGSNKIVSYEFIAGKKNEKYIIEIRVKLTDRTQHDVRFEAENAEELNGLIAEIEQRIKTIE\n",
      "seq63: EMKRELTIDSIPEIMIKLNQIKTSRSLLPEINFRIDQNSFSRIMAEGIYRSARYAGGDTKSWYTIDSYLNSPSTMEFSIEFINRQDLLHLNFQIHRSDNSEGLLELSAEDFDSFQSFIDKLETALSNLV\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(ret_):\n",
    "    protoken_idx = np.array(r['protoken_indexes'])[:seq_len]\n",
    "    aatype_idx = np.array(r['aatype_indexes'])[:seq_len]\n",
    "    print('seq{}: {}'.format(i, ''.join(aatype_index_to_resname(aatype_idx))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Structure Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 21:14:25.706101: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now inference pdbs at: ..//example_scripts/results/contextual_scaffolding, \n",
      "Example: ..//example_scripts/results/contextual_scaffolding/5jxe_G_VH.pdb\n",
      "Total validation pdb number: 1\n",
      "Saving pdb at: ..//example_scripts/results/contextual_scaffolding/stage_1/inference_pdbs, \n",
      "Example: ..//example_scripts/results/contextual_scaffolding/stage_1/inference_pdbs/5jxe_G_VH.pdb\n",
      "\tBATCH_SIZE: 16\n",
      "==============now processing 0 to 1===============\n",
      "pdb names in every device:  5jxe_G_VH\n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "pdb names in every device:  \n",
      "Not enough data for sharding, extend the last data.\n",
      "VALID_DATA_NUM: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 21:16:46.899637: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 6; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-13 21:16:46.899680: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 3; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-13 21:16:46.899707: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 4; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-13 21:16:46.899728: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 2; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-13 21:16:46.899753: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 5; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-13 21:16:46.899778: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 0; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-13 21:16:46.899799: E external/xla/xla/service/rendezvous.cc:38] This thread has been waiting for `initialize clique for rank 7; clique=devices=[0,1,2,3,4,5,6,7]; stream=0; run_id=1259322816` for 10 seconds and may be stuck. Expected 8 threads to join the rendezvous, but not all of them arrived on time.\n",
      "2025-01-13 21:17:24.864343: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-13 21:17:24.864446: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-13 21:17:24.864498: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-13 21:17:24.864569: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-13 21:17:24.864602: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-13 21:17:24.864638: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n",
      "2025-01-13 21:17:24.864699: E external/xla/xla/service/rendezvous.cc:45] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdb saved at: ..//example_scripts/results/contextual_scaffolding/stage_1/inference_pdbs/5jxe_G_VH.pdb \n",
      "seq_len: 218\n",
      "preprocessing time: 24.317128s\n",
      "inference time: 83.330078s\n",
      "code_usage: 0.033203125\n",
      "total time: 107.647206s\n",
      "seq_len_max: 218, seq_len_min: 218\n",
      "stage_1 finished.\n",
      "pdb, loss_aux, seq_len_dict, vq_code_indexes_dict saved at ..//example_scripts/results/contextual_scaffolding/stage_1\n",
      "All finished.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### example: 5jxe_G_VH \n",
    "\n",
    "### obatin ProTokens\n",
    "working_dir = '../'\n",
    "os.system(f'''export PYTHONPATH={working_dir}/PROTOKEN\n",
    "          python {working_dir}/PROTOKEN/scripts/infer_batch.py\\\n",
    "            --encoder_config {working_dir}/PROTOKEN/config/encoder.yaml\\\n",
    "            --decoder_config {working_dir}/PROTOKEN/config/decoder.yaml\\\n",
    "            --vq_config {working_dir}/PROTOKEN/config/vq.yaml\\\n",
    "            --pdb_dir_path {working_dir}/example_scripts/results/contextual_scaffolding\\\n",
    "            --save_dir_path {working_dir}/example_scripts/results/contextual_scaffolding\\\n",
    "            --load_ckpt_path {working_dir}/ckpts/protoken_params_100000.pkl''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_mask (218,) bool\n",
      "residue_index (218,) int32\n"
     ]
    }
   ],
   "source": [
    "### load context\n",
    "with open('./results/contextual_scaffolding/stage_1/generator_inputs/5jxe_G_VH.pkl', 'rb') as f:\n",
    "    data_dict = pkl.load(f)\n",
    "\n",
    "seq_len = len(data_dict['protokens'])\n",
    "seq_mask = np.ones(seq_len, dtype=np.bool_)\n",
    "residue_index = np.arange(seq_len, dtype=np.int32)\n",
    "protoken_context = data_dict['protokens'].astype(np.int32)\n",
    "aatype_context = data_dict['aatype'].astype(np.int32)\n",
    "\n",
    "input_dict = {\n",
    "    'seq_mask': seq_mask, 'residue_index': residue_index,\n",
    "}\n",
    "\n",
    "for k, v in input_dict.items(): print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select CDR3 as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def parse_annotation(annotation_file, aatype_indexes):\n",
    "    seq_str = aatype_index_to_resname(aatype_indexes)\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        contents = f.readlines()\n",
    "        annotation_dict = ast.literal_eval(contents[0])\n",
    "    annotation_resid_dict = {}\n",
    "    for k, v in annotation_dict.items():\n",
    "        start_id = seq_str.find(v)\n",
    "        if start_id == -1:\n",
    "            raise ValueError('can not find {} in {}'.format(v, seq_str))\n",
    "        end_id = start_id + len(v)\n",
    "        annotation_resid_dict[k] = np.arange(start_id, end_id)\n",
    "        \n",
    "    return annotation_resid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repaint_context (218, 40) float32\n",
      "repaint_mask (218, 40) float32\n"
     ]
    }
   ],
   "source": [
    "annotation_resid_dict = parse_annotation('./results/contextual_scaffolding/5jxe_G_VH_annotation.txt', \n",
    "                                         aatype_context)\n",
    "\n",
    "### select H-CDR3 as context\n",
    "protoken_context_resids = annotation_resid_dict['H-CDR3']\n",
    "aatype_context_resids = annotation_resid_dict['H-CDR3']\n",
    "\n",
    "repaint_context, repaint_mask = make_repaint_info(aatype_context, protoken_context, aatype_context_resids, protoken_context_resids)\n",
    "\n",
    "repaint_dict = {\n",
    "    'repaint_context': repaint_context, 'repaint_mask': repaint_mask.astype(np.float32)\n",
    "}\n",
    "for k, v in repaint_dict.items(): print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residue_index (8, 8, 512) int32\n",
      "seq_mask (8, 8, 512) bool\n",
      "x (8, 8, 512, 40) float32\n",
      "repaint_context (8, 8, 512, 40) float32\n",
      "repaint_mask (8, 8, 512, 40) float32\n"
     ]
    }
   ],
   "source": [
    "### preprocessing inputs\n",
    "\n",
    "def reshape_tile_pad_x(x):\n",
    "    x_shape = x.shape\n",
    "    x = np.pad(x, ((0, NRES - x_shape[0]), ) + ((0,0),) * (len(x_shape) - 1))\n",
    "    x_shape = x.shape\n",
    "    \n",
    "    x = np.tile(x[None, ...], (BATCH_SIZE, ) + (1, ) * len(x_shape))\n",
    "    x = x.reshape(NDEVICES, NSAMPLE_PER_DEVICE, *x_shape)\n",
    "    return x\n",
    "\n",
    "input_dict = jax.tree.map(\n",
    "    lambda x: jnp.array(reshape_tile_pad_x(x)), input_dict\n",
    ")\n",
    "repaint_dict = jax.tree.map(\n",
    "    lambda x: jnp.array(reshape_tile_pad_x(x)), repaint_dict\n",
    ")\n",
    "\n",
    "init_key, rng_key = jax.random.split(rng_key)\n",
    "x = jax.random.normal(init_key, (NDEVICES, NSAMPLE_PER_DEVICE, NRES, DIM_EMB))\n",
    "input_dict['x'] = x\n",
    "\n",
    "rng_keys, rng_key = split_multiple_rng_keys(rng_key, NDEVICES)\n",
    "rng_keys = jnp.reshape(rng_keys, (NDEVICES, -1))\n",
    "\n",
    "for k, v in input_dict.items(): print(k, v.shape, v.dtype)\n",
    "for k, v in repaint_dict.items(): print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [16:47<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "ret = run_infer(input_dict['x'], input_dict['seq_mask'], input_dict['residue_index'], rng_keys,\n",
    "                repaint_dict['repaint_context'], repaint_dict['repaint_mask'])\n",
    "\n",
    "ret = jax.tree_util.tree_map(lambda x: np.array(x.reshape(BATCH_SIZE, *x.shape[2:])).tolist(), ret)\n",
    "with open('results/contextual_scaffolding/result.pkl', 'wb') as f:\n",
    "    pkl.dump(ret, f)\n",
    "    \n",
    "ret_ = flatten_list_of_dicts([ret])\n",
    "with open('results/contextual_scaffolding/result_flatten.pkl', 'wb') as f:\n",
    "    pkl.dump(ret_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 10:39:30.279075: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding structures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:05<00:00, 65.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving structures to .pdbs...\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_dir = '../'\n",
    "\n",
    "os.system(f'''export PYTHONPATH={working_dir}/PROTOKEN\n",
    "          python {working_dir}/PROTOKEN/scripts/decode_structure.py\\\n",
    "                --decoder_config {working_dir}/PROTOKEN/config/decoder.yaml\\\n",
    "                --vq_config {working_dir}/PROTOKEN/config/vq.yaml\\\n",
    "                --input_path results/contextual_scaffolding/result_flatten.pkl\\\n",
    "                --output_dir results/contextual_scaffolding/pdb\\\n",
    "                --load_ckpt_path {working_dir}/ckpts/protoken_params_100000.pkl\\\n",
    "                --padding_len {NRES}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
